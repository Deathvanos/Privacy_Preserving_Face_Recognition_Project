{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T10:24:09.303752Z",
     "start_time": "2025-04-26T10:24:09.294789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import controller.ml_controller as ml\n",
    "MODEL_SAVE_DIR = r'..\\data\\ml_models\\trained'\n",
    "LOG_DIR = r'..\\data\\ml_models\\logs'\n",
    "DB_PATH = r\"..\\data\\gui_database.db\""
   ],
   "id": "be8f4dd325ae10e6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T10:24:13.478956Z",
     "start_time": "2025-04-26T10:24:13.471531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aucune des variables ici n'est utilisé. Les valeurs ont été implementées en input des fonctions\n",
    "# --- Chemins et Noms ---\n",
    "ANONY_IMAGES_PATH = 'data/reconstructed_pipeline'\n",
    "MODEL_NAME = 'simple_cnn_lfw_anony_v1'\n",
    "# --- Paramètres des Données et Prétraitement ---\n",
    "COLOR_MODE = 'grayscale'\n",
    "IMG_WIDTH, IMG_HEIGHT, CHANNELS = (100, 100, 1 if COLOR_MODE == 'grayscale' else 3)\n",
    "# --- Paramètres de Division des Données ---\n",
    "SPLIT_STRATEGY = 'stratified'\n",
    "# -- Pour 'stratified' --\n",
    "TEST_SPLIT_RATIO = 0.2\n",
    "VALIDATION_SPLIT_RATIO = 0.15\n",
    "# -- Pour 'fixed_per_subject' --\n",
    "N_TRAIN_PER_SUBJECT = 16\n",
    "RANDOM_STATE = 42\n",
    "# ---    Paramètres du Modèle ---\n",
    "MODEL_ARCHITECTURE = 'simple_cnn'\n",
    "# -- Pour Transfer Learning (si MODEL_ARCHITECTURE commence par 'transfer_') --\n",
    "TRANSFER_BASE_MODEL_NAME = 'MobileNetV2'\n",
    "TRANSFER_FREEZE_BASE = True\n",
    "# --- Paramètres d'Entraînement ---\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "EARLY_STOPPING_PATIENCE = 10"
   ],
   "id": "cb4e96e88d85faa6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data from folder (LFW dataset)",
   "id": "60ff5ecf4cd4d651"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:58:08.927303Z",
     "start_time": "2025-04-25T15:58:08.779151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "RECONSTRUCTED_DIR = r\"..\\data\\reconstructed_pipeline\"\n",
    "os.makedirs(RECONSTRUCTED_DIR, exist_ok=True)\n",
    "\n",
    "X, y, label_encoder = ml.data_loader.load_anonymized_images_flat(\n",
    "    data_dir=RECONSTRUCTED_DIR,\n",
    "    img_width=IMG_WIDTH,\n",
    "    img_height=IMG_HEIGHT,\n",
    "    color_mode='grayscale'\n",
    ")"
   ],
   "id": "8002dc5917cfa4a5",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m RECONSTRUCTED_DIR = \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m..\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m\\\u001B[39m\u001B[33mreconstructed_pipeline\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      3\u001B[39m os.makedirs(RECONSTRUCTED_DIR, exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m X, y, label_encoder = \u001B[43mml\u001B[49m.data_loader.load_anonymized_images_flat(\n\u001B[32m      6\u001B[39m     data_dir=RECONSTRUCTED_DIR,\n\u001B[32m      7\u001B[39m     img_width=IMG_WIDTH,\n\u001B[32m      8\u001B[39m     img_height=IMG_HEIGHT,\n\u001B[32m      9\u001B[39m     color_mode=\u001B[33m'\u001B[39m\u001B[33mgrayscale\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     10\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'ml' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data from database",
   "id": "ca308921b6a78a8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T10:24:23.826536Z",
     "start_time": "2025-04-26T10:24:23.655333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get data from db\n",
    "X, y, label_encoder = ml.get_and_prepare_data(DB_PATH)\n",
    "input_shape = X[0].shape ;# pas bon - use this insted: IMG_WIDTH, IMG_HEIGHT, CHANNELS\n",
    "#input_shape = (IMG_WIDTH, IMG_HEIGHT, CHANNELS)\n",
    "print(X.shape)"
   ],
   "id": "f02e202882b7083f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467, 100, 100, 3)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T10:24:30.613762Z",
     "start_time": "2025-04-26T10:24:30.360473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the model\n",
    "model = ml.train_model(X, y, label_encoder, input_shape=(input_shape), model_save_dir=MODEL_SAVE_DIR, log_dir=LOG_DIR)"
   ],
   "id": "2f03b18e7064be29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Division des données : test_size=0.2, validation_size=0.15\n",
      "Taille Test: 94 échantillons\n",
      "Taille Entraînement: 303 échantillons\n",
      "Taille Validation: 70 échantillons\n",
      "Construction du modèle CNN simple avec input_shape=(100, 100, 1) et num_classes=43\n",
      "Modèle CNN simple construit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erreur pendant l'entraînement : Exception encountered when calling Functional.call().\n",
      "\n",
      "\u001B[1mInput 0 of layer \"conv1_1\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 100, 100, 3)\u001B[0m\n",
      "\n",
      "Arguments received by Functional.call():\n",
      "  • inputs=tf.Tensor(shape=(None, 100, 100, 3), dtype=uint8)\n",
      "  • training=True\n",
      "  • mask=None\n",
      "\n",
      "Sauvegarde de l'encodeur de labels (même si l'entraînement a échoué)...\n",
      "LabelEncoder sauvegardé dans : ..\\data\\models\\trained\\simple_cnn_lfw_anony_v1_label_encoder.joblib\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T09:59:32.965223Z",
     "start_time": "2025-04-26T09:59:32.958671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"summary_text: {model['summary_text']}\")\n",
    "print(f\"duration: {model['duration']}\")\n",
    "print(f\"evaluation: {model['evaluation']}\")\n",
    "print(f\"training_plot: {model['training_plot']}\") # .show()"
   ],
   "id": "c39596238fe36385",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_text: Model: \"simple_cnn\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ input_image (InputLayer)        │ (None, 100, 100, 3)    │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1_1 (Conv2D)                │ (None, 100, 100, 32)   │           896 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ bn1_1 (BatchNormalization)      │ (None, 100, 100, 32)   │           128 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv1_2 (Conv2D)                │ (None, 100, 100, 32)   │         9,248 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ bn1_2 (BatchNormalization)      │ (None, 100, 100, 32)   │           128 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ pool1 (MaxPooling2D)            │ (None, 50, 50, 32)     │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ drop1 (Dropout)                 │ (None, 50, 50, 32)     │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2_1 (Conv2D)                │ (None, 50, 50, 64)     │        18,496 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ bn2_1 (BatchNormalization)      │ (None, 50, 50, 64)     │           256 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ conv2_2 (Conv2D)                │ (None, 50, 50, 64)     │        36,928 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ bn2_2 (BatchNormalization)      │ (None, 50, 50, 64)     │           256 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ pool2 (MaxPooling2D)            │ (None, 25, 25, 64)     │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ drop2 (Dropout)                 │ (None, 25, 25, 64)     │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ flatten (Flatten)               │ (None, 40000)          │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense1 (Dense)                  │ (None, 128)            │     5,120,128 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ bn_dense1 (BatchNormalization)  │ (None, 128)            │           512 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ drop_dense1 (Dropout)           │ (None, 128)            │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ output_softmax (Dense)          │ (None, 43)             │         5,547 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 5,192,523 (19.81 MB)\n",
      " Trainable params: 5,191,883 (19.81 MB)\n",
      " Non-trainable params: 640 (2.50 KB)\n",
      "\n",
      "\n",
      "duration: 169.58463883399963\n",
      "evaluation: {'loss': 2.104935884475708, 'accuracy': 0.41489362716674805}\n",
      "training_plot: <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=1200x500 at 0x1598A866F60>\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:00:42.427831Z",
     "start_time": "2025-04-25T16:00:42.191899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Image to predict\n",
    "index = 30\n",
    "\n",
    "img_to_predict = X[index]\n",
    "true_result = y[index]\n",
    "print(img_to_predict.shape)\n",
    "\n",
    "# Make a prediction\n",
    "prediction = ml.predict_image(img_to_predict, model_save_dir=MODEL_SAVE_DIR)\n",
    "\n",
    "# Result\n",
    "print(f\"prediction: {prediction}\")\n",
    "print(f\"true_result: {true_result}\")\n",
    "print(f\"The model is correct: {prediction==true_result}\")"
   ],
   "id": "d94c3b5b28aa82e3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder chargé depuis : ..\\data\\models\\trained\\simple_cnn_lfw_anony_v1_label_encoder.joblib\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 111ms/step\n",
      "prediction: 18\n",
      "true_result: 2\n",
      "The model is correct: False\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
