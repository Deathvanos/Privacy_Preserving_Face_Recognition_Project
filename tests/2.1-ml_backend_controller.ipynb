{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "c58dae2925de0a3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import src.face_recognition.ml_models as ml_models\n",
    "import src.modules.data_loader as data_loader\n",
    "import src.config as config\n",
    "\n",
    "config.ANONY_IMAGES_PATH = '../data/dataset-lfw_reconstructed'\n",
    "ML_OUTPUT = r\"..\\data\\ml_models\"\n",
    "config.MODEL_SAVE_DIR = f'{ML_OUTPUT}/trained'\n",
    "config.LOG_DIR = f'{ML_OUTPUT}/logs'\n",
    "config.IMG_WIDTH, config.IMG_HEIGHT, config.CHANNELS = (100, 100, 1)\n",
    "\n"
   ],
   "id": "dad1014640b10f77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"--- Démarrage du Script d'Entraînement ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- 1. Chargement de la Configuration ---\n",
    "print(\"Configuration chargée depuis config.py:\")\n",
    "print(f\"  - Dossier Données: {config.ANONY_IMAGES_PATH}\")\n",
    "print(f\"  - Dossier Sauvegarde Modèles: {config.MODEL_SAVE_DIR}\")\n",
    "print(f\"  - Architecture Modèle: {config.MODEL_ARCHITECTURE}\")\n",
    "print(f\"  - Nom Modèle: {config.MODEL_NAME}\")\n",
    "print(f\"  - Dimensions Image: {config.IMG_HEIGHT}x{config.IMG_WIDTH}x{config.CHANNELS}\")\n",
    "print(f\"  - Stratégie Split: {config.SPLIT_STRATEGY}\")\n",
    "print(f\"  - Époques: {config.EPOCHS}, Batch Size: {config.BATCH_SIZE}\")\n",
    "\n",
    "os.makedirs(config.MODEL_SAVE_DIR, exist_ok=True)\n",
    "if hasattr(config, 'LOG_DIR') and config.LOG_DIR:\n",
    "    os.makedirs(config.LOG_DIR, exist_ok=True)\n",
    "    print(f\"  - Dossier Logs TensorBoard: {config.LOG_DIR}\")\n"
   ],
   "id": "b0e82e66df25d313",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 2. Chargement et Préparation des Données ---\n",
    "print(\"\\n--- Chargement des données ---\")\n",
    "X, y, label_encoder = data_loader.load_anonymized_images_flat(\n",
    "    data_dir=config.ANONY_IMAGES_PATH,\n",
    "    img_width=config.IMG_WIDTH,\n",
    "    img_height=config.IMG_HEIGHT,\n",
    "    color_mode=config.COLOR_MODE\n",
    ")\n",
    "\n",
    "if X is None or y is None or label_encoder is None:\n",
    "    print(\"Erreur critique lors du chargement des données. Arrêt du script.\")\n",
    "\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "input_shape = (config.IMG_HEIGHT, config.IMG_WIDTH, config.CHANNELS)\n",
    "print(f\"Nombre de classes détectées : {num_classes}\")"
   ],
   "id": "6342e4d0c705d44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 3. Division des Données ---\n",
    "print(\"\\n--- Division des données ---\")\n",
    "X_train, y_train = None, None\n",
    "X_val, y_val = None, None\n",
    "X_test, y_test = None, None\n",
    "\n",
    "if config.SPLIT_STRATEGY == 'stratified':\n",
    "    data_splits = data_loader.split_data_stratified(\n",
    "        X, y,\n",
    "        test_size=config.TEST_SPLIT_RATIO,\n",
    "        validation_size=config.VALIDATION_SPLIT_RATIO,\n",
    "        random_state=config.RANDOM_STATE\n",
    "    )\n",
    "    X_train = data_splits.get('X_train')\n",
    "    y_train = data_splits.get('y_train')\n",
    "    X_val = data_splits.get('X_val')\n",
    "    y_val = data_splits.get('y_val')\n",
    "    X_test = data_splits.get('X_test')\n",
    "    y_test = data_splits.get('y_test')\n",
    "\n",
    "    if X_val is None and config.VALIDATION_SPLIT_RATIO > 0 and X_train is not None and len(X_train) > 0:\n",
    "         val_ratio_from_train = config.VALIDATION_SPLIT_RATIO / (1.0 - config.TEST_SPLIT_RATIO)\n",
    "         if val_ratio_from_train < 1.0:\n",
    "             print(f\"Création du set de validation depuis l'entraînement (ratio: {val_ratio_from_train:.2f})\")\n",
    "             X_train, X_val, y_train, y_val = train_test_split(\n",
    "                 X_train, y_train,\n",
    "                 test_size=val_ratio_from_train,\n",
    "                 random_state=config.RANDOM_STATE,\n",
    "                 stratify=y_train\n",
    "             )\n",
    "         else:\n",
    "             print(\"Attention: Ratios de split incohérents, pas de données d'entraînement restantes après validation.\")\n",
    "\n",
    "elif config.SPLIT_STRATEGY == 'fixed_per_subject':\n",
    "    X_train_full, X_test, y_train_full, y_test = data_loader.split_data_fixed_per_subject(\n",
    "        X, y,\n",
    "        n_train_per_class=config.N_TRAIN_PER_SUBJECT,\n",
    "        random_state=config.RANDOM_STATE\n",
    "    )\n",
    "    if config.VALIDATION_SPLIT_RATIO > 0 and X_train_full is not None and len(X_train_full) > 0:\n",
    "        print(f\"Création du set de validation depuis l'entraînement (ratio: {config.VALIDATION_SPLIT_RATIO})\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train_full, y_train_full,\n",
    "            test_size=config.VALIDATION_SPLIT_RATIO,\n",
    "            random_state=config.RANDOM_STATE,\n",
    "            stratify=y_train_full\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train = X_train_full, y_train_full\n",
    "        X_val, y_val = None, None\n",
    "\n",
    "else:\n",
    "    print(f\"Erreur: Stratégie de split '{config.SPLIT_STRATEGY}' non reconnue.\")\n",
    "\n",
    "if X_train is None or len(X_train) == 0:\n",
    "    print(\"Erreur: Aucune donnée d'entraînement disponible après la division.\")\n",
    "\n",
    "if X_val is None or len(X_val) == 0:\n",
    "    print(\"Attention: Aucune donnée de validation disponible. L'entraînement se fera sans suivi de validation.\")\n",
    "    validation_data = None # `fit` utilisera pas de validation\n",
    "else:\n",
    "    validation_data = (X_val, y_val)\n",
    "    print(f\"Taille finale - Entraînement: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test) if X_test is not None else 0}\")"
   ],
   "id": "a004ac439d0a45e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 4. Construction du Modèle ---\n",
    "print(\"\\n--- Construction du modèle ---\")\n",
    "model = None\n",
    "if config.MODEL_ARCHITECTURE == 'simple_cnn':\n",
    "    model = ml_models.build_simple_cnn(input_shape=input_shape, num_classes=num_classes)\n",
    "elif config.MODEL_ARCHITECTURE.startswith('transfer_'):\n",
    "    base_name = getattr(config, 'TRANSFER_BASE_MODEL_NAME', 'MobileNetV2')\n",
    "    freeze = getattr(config, 'TRANSFER_FREEZE_BASE', True)\n",
    "    print(f\"Utilisation du modèle de base: {base_name}, Freeze: {freeze}\")\n",
    "    model = ml_models.build_transfer_model(input_shape=input_shape,\n",
    "                                           num_classes=num_classes,\n",
    "                                           base_model_name=base_name,\n",
    "                                           freeze_base=freeze)\n",
    "else:\n",
    "    print(f\"Erreur: Architecture de modèle non reconnue dans config: {config.MODEL_ARCHITECTURE}\")\n",
    "\n",
    "if model is None:\n",
    "    print(\"Erreur critique lors de la construction du modèle. Arrêt.\")\n",
    "\n",
    "# --- 5. Compilation du Modèle ---\n",
    "print(\"\\n--- Compilation du modèle ---\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=config.LEARNING_RATE)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(\"Modèle compilé avec Adam optimizer.\")\n",
    "model.summary()"
   ],
   "id": "3bd2a477de143b2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 6. Configuration des Callbacks ---\n",
    "print(\"\\n--- Configuration des Callbacks ---\")\n",
    "callbacks = []\n",
    "\n",
    "model_filename = f\"{config.MODEL_NAME}.h5\"\n",
    "model_filepath = os.path.join(config.MODEL_SAVE_DIR, model_filename)\n",
    "print(f\"  - ModelCheckpoint: Sauvegarde du meilleur modèle dans {model_filepath}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "callbacks.append(checkpoint_callback)\n",
    "\n",
    "if hasattr(config, 'EARLY_STOPPING_PATIENCE') and config.EARLY_STOPPING_PATIENCE > 0:\n",
    "    print(f\"  - EarlyStopping: Activé avec patience={config.EARLY_STOPPING_PATIENCE}\")\n",
    "    early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=config.EARLY_STOPPING_PATIENCE,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(early_stopping_callback)\n",
    "else:\n",
    "    print(\"  - EarlyStopping: Désactivé.\")\n",
    "\n",
    "\n",
    "if hasattr(config, 'LOG_DIR') and config.LOG_DIR:\n",
    "    tensorboard_log_dir = os.path.join(config.LOG_DIR, config.MODEL_NAME + \"_\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    print(f\"  - TensorBoard: Logs dans {tensorboard_log_dir}\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=tensorboard_log_dir,\n",
    "        histogram_freq=1\n",
    "    )\n",
    "    callbacks.append(tensorboard_callback)\n",
    "else:\n",
    "    print(\"  - TensorBoard: Désactivé.\")\n",
    "\n",
    "csv_log_path = os.path.join(config.MODEL_SAVE_DIR, f\"{config.MODEL_NAME}_training_log.csv\")\n",
    "print(f\"  - CSVLogger: Logs dans {csv_log_path}\")\n",
    "csv_logger_callback = tf.keras.callbacks.CSVLogger(csv_log_path, append=False)\n",
    "callbacks.append(csv_logger_callback)"
   ],
   "id": "46d36bc7bc2ca350",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 7. Entraînement du Modèle ---\n",
    "print(\"\\n--- Démarrage de l'entraînement ---\")\n",
    "history = None\n",
    "try:\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=config.EPOCHS,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"--- Entraînement terminé ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur pendant l'entraînement : {e}\")\n",
    "    encoder_save_path = os.path.join(config.MODEL_SAVE_DIR, f\"{config.MODEL_NAME}_label_encoder.joblib\")\n",
    "    print(\"\\nSauvegarde de l'encodeur de labels (même si l'entraînement a échoué)...\")\n",
    "    data_loader.save_label_encoder(label_encoder, encoder_save_path)"
   ],
   "id": "7d5300d0bb116b4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 8. Post-Entraînement ---\n",
    "encoder_save_path = os.path.join(config.MODEL_SAVE_DIR, f\"{config.MODEL_NAME}_label_encoder.joblib\")\n",
    "print(\"\\n--- Sauvegarde de l'encodeur de labels ---\")\n",
    "data_loader.save_label_encoder(label_encoder, encoder_save_path)\n",
    "\n",
    "if history is not None:\n",
    "    print(\"\\n--- Affichage des courbes d'apprentissage ---\")\n",
    "    try:\n",
    "        acc = history.history['accuracy']\n",
    "        loss = history.history['loss']\n",
    "        epochs_range = range(len(acc))\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "        if validation_data: # Seulement si validation existe\n",
    "             val_acc = history.history['val_accuracy']\n",
    "             plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs_range, loss, label='Training Loss')\n",
    "        if validation_data: # Seulement si validation existe\n",
    "            val_loss = history.history['val_loss']\n",
    "            plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        plot_save_path = os.path.join(config.MODEL_SAVE_DIR, f\"{config.MODEL_NAME}_training_curves.pdf\")\n",
    "        plt.savefig(plot_save_path, format='pdf', bbox_inches='tight')\n",
    "        print(f\"Courbes sauvegardées dans : {plot_save_path}\")\n",
    "\n",
    "    except Exception as plot_e:\n",
    "        print(f\"Erreur lors de la génération/sauvegarde des courbes: {plot_e}\")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"\\n--- Script d'Entraînement Terminé en {duration:.2f} secondes ---\")\n",
    "print(f\"Le meilleur modèle devrait être sauvegardé dans : {model_filepath}\")\n",
    "print(f\"L'encodeur de labels est sauvegardé dans : {encoder_save_path}\")\n",
    "\n"
   ],
   "id": "52021639fc4844b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Predict",
   "id": "cc9ee36ea101e496"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Optional\n",
    "from PIL import Image\n",
    "\n",
    "user = 5\n",
    "image_path = f\"../data/dataset-lfw_reconstructed/reconstructed_{user}_2.png\""
   ],
   "id": "b33999dcd2ce82a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"--- Démarrage du Script de Prédiction ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- 1. Charger Configuration et Chemins ---\n",
    "print(\"Chargement de la configuration...\")\n",
    "model_filename = f\"{config.MODEL_NAME}.h5\" # ou .keras\n",
    "model_filepath = os.path.join(config.MODEL_SAVE_DIR, model_filename)\n",
    "encoder_filename = f\"{config.MODEL_NAME}_label_encoder.joblib\"\n",
    "encoder_filepath = os.path.join(config.MODEL_SAVE_DIR, encoder_filename)\n",
    "\n",
    "print(f\"  - Modèle utilisé: {model_filepath}\")\n",
    "print(f\"  - Encodeur utilisé: {encoder_filepath}\")\n",
    "print(f\"  - Image à prédire: {image_path}\")"
   ],
   "id": "8b52d85a2b88db70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 2. Charger Modèle et Encodeur ---\n",
    "print(\"\\n--- Chargement du modèle et de l'encodeur ---\")\n",
    "if not os.path.exists(model_filepath):\n",
    "    print(f\"Erreur: Fichier modèle non trouvé: {model_filepath}\")\n",
    "try:\n",
    "    model = tf.keras.models.load_model(model_filepath)\n",
    "    print(\"Modèle chargé avec succès.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du modèle Keras: {e}\")\n",
    "\n",
    "# Charger l'encodeur de labels\n",
    "label_encoder = data_loader.load_label_encoder(encoder_filepath)\n",
    "if label_encoder is None:\n",
    "    print(\"Erreur critique : Impossible de charger l'encodeur de labels.\")"
   ],
   "id": "3ec5e7fe31a3d72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 3. Prétraiter l'Image d'Entrée ---\n",
    "\n",
    "def preprocess_single_image(\n",
    "    image_path: str,\n",
    "    img_width: int,\n",
    "    img_height: int,\n",
    "    color_mode: str\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Charge, redimensionne, normalise et formate une image unique pour la prédiction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        pil_mode = 'L' if color_mode == 'grayscale' else 'RGB'\n",
    "        img_converted = img.convert(pil_mode)\n",
    "\n",
    "        img_resized = img_converted.resize((img_width, img_height))\n",
    "\n",
    "        img_array = np.array(img_resized)\n",
    "\n",
    "        img_normalized = img_array.astype('float32') / 255.0\n",
    "\n",
    "        if color_mode == 'grayscale':\n",
    "            img_final = np.expand_dims(img_normalized, axis=-1)\n",
    "        else:\n",
    "            img_final = img_normalized\n",
    "\n",
    "        img_batch = np.expand_dims(img_final, axis=0)\n",
    "\n",
    "        print(f\"Image prétraitée, shape final: {img_batch.shape}\")\n",
    "        return img_batch\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur: Fichier image introuvable : {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du prétraitement de l'image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"\\n--- Prétraitement de l'image d'entrée ---\")\n",
    "preprocessed_image = preprocess_single_image(\n",
    "    image_path=image_path,\n",
    "    img_width=config.IMG_WIDTH,\n",
    "    img_height=config.IMG_HEIGHT,\n",
    "    color_mode=config.COLOR_MODE\n",
    ")\n",
    "\n",
    "if preprocessed_image is None:\n",
    "    print(\"Échec du prétraitement de l'image.\")"
   ],
   "id": "681a354b97fc7bbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 4. Faire la Prédiction ---\n",
    "print(\"\\n--- Prédiction ---\")\n",
    "try:\n",
    "    prediction_probabilities = model.predict(preprocessed_image)\n",
    "\n",
    "    predicted_index = np.argmax(prediction_probabilities[0])\n",
    "    prediction_confidence = prediction_probabilities[0][predicted_index]\n",
    "\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_index])[0]\n",
    "\n",
    "    print(\"\\n--- Résultat de la Prédiction ---\")\n",
    "    print(f\"  - Image : {os.path.basename(image_path)}\")\n",
    "    print(f\"  - Identité Prédite (Subject ID) : {predicted_label}\")\n",
    "    print(f\"  - Confiance : {prediction_confidence:.4f} ({prediction_confidence*100:.2f}%)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la prédiction: {e}\")\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"\\n--- Script de Prédiction Terminé en {duration:.2f} secondes ---\")\n",
    "\n",
    "print(predicted_label)"
   ],
   "id": "f42f575e8421b215",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
