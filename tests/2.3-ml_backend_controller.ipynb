{
 "cells": [
  {
   "cell_type": "code",
   "id": "153d065b7c437ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T16:39:59.635757Z",
     "start_time": "2025-04-29T16:39:56.319381Z"
    }
   },
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import float32\n",
    "from tensorflow.image import resize, rgb_to_grayscale, convert_image_dtype\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, CSVLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from config import IMG_HEIGHT, IMG_WIDTH\n",
    "from src.modules import data_loader\n",
    "from src.face_recognition import ml_models\n",
    "\n",
    "\n",
    "################## PATH ##################\n",
    "DB_PATH = r\"..\\data\\gui_database.db\"\n",
    "LFW_DATASET_PATH = r\"..\\data\\dataset-lfw_reconstructed\"\n",
    "ML_OUTPUT = r\"..\\data\\ml_models\"\n",
    "MODEL_SAVE_DIR = f'{ML_OUTPUT}/trained'\n",
    "LOG_DIR = f'{ML_OUTPUT}/logs'\n",
    "\n",
    "\n",
    "############# MODEL SETTINGS #############\n",
    "#####--- prepare_data_train_model ---#####\n",
    "INPUT_SHAPE = (100, 100, 1)\n",
    "IMG_WIDTH, IMG_HEIGHT, CHANNELS = INPUT_SHAPE\n",
    "SPLIT_STRATEGY = 'stratified'\n",
    "TEST_SPLIT_RATIO = 0.2\n",
    "VALIDATION_SPLIT_RATIO = 0.15\n",
    "RANDOM_STATE = 42\n",
    "N_TRAIN_PER_SUBJECT = 7\n",
    "#####--- create_model ---#####\n",
    "MODEL_NAME = 'simple_cnn_lfw_anony_v1'\n",
    "MODEL_ARCHITECTURE = 'simple_cnn'\n",
    "LEARNING_RATE = 0.001\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "TRANSFER_BASE_MODEL_NAME = 'MobileNetV2'\n",
    "TRANSFER_FREEZE_BASE = True\n",
    "#####--- train_model ---#####\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "##########################################"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "e80ea5458bc51b58",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Noised DB dataset",
   "id": "158d3c697c8fa35d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import controller.ml_controller as mlc\n",
    "\n",
    "X, y, label_encoder = mlc.MLController.get_data_from_db(DB_PATH)\n",
    "print(f\"(nb_image, width, height, channels) : {X.shape}\")"
   ],
   "id": "a4bd8fb06683e169",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Noised LFW dataset",
   "id": "8f9dbd59bd7c7471"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.modules.data_loader import load_anonymized_images_flat\n",
    "os.makedirs(LFW_DATASET_PATH, exist_ok=True)\n",
    "\n",
    "X, y, label_encoder = load_anonymized_images_flat(\n",
    "    data_dir=LFW_DATASET_PATH,\n",
    "    img_width=IMG_WIDTH,\n",
    "    img_height=IMG_HEIGHT,\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "if not X.shape and not y.shape and not label_encoder:\n",
    "    raise ValueError('Critical error while loading data. Script stopped..')\n",
    "print(f\"\\n(nb_image, width, height, channels) : {X.shape}\")"
   ],
   "id": "61d47265b29e5f8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "842a3ffb71c41754",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def formate_ml_image(\n",
    "    image: np.array,\n",
    "    img_width: int,\n",
    "    img_height: int,\n",
    "    keep_rgb_channels: bool=False\n",
    "    ):\n",
    "    # Convert to grayscale\n",
    "    if image.ndim == 2:\n",
    "        image = image[..., np.newaxis]\n",
    "    elif image.shape[2] == 3:\n",
    "        if not keep_rgb_channels:\n",
    "            image = rgb_to_grayscale(image).numpy()\n",
    "    elif image.shape[2] != 1:\n",
    "        raise ValueError(\"Image must be grayscale or RGB.\")\n",
    "    # Resize & normalize image\n",
    "    image = convert_image_dtype(image, dtype=float32)\n",
    "    image = resize(image, [img_width, img_height], method=\"area\").numpy()\n",
    "    return image\n",
    "\n",
    "def prepare_data_train_model(\n",
    "    X, y, label_encoder,\n",
    "    input_shape=(100, 100),\n",
    "    split_strategy='stratified',\n",
    "    test_split_ratio=0.2,\n",
    "    validation_split_ratio=0.15,\n",
    "    random_state=42,\n",
    "    n_train_per_subject=7,\n",
    "    show_logs=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Prepare data for facial recognition model.\n",
    "\n",
    "    --- Images & labels set & image size\n",
    "    :param X: dataset (numpy array of images)\n",
    "    :param y: labels\n",
    "    :param label_encoder: sklearn.preprocessing._label.LabelEncoder\n",
    "    :param input_shape:  (width, height) of images.\n",
    "    --- Data Division Settings ---\n",
    "    :param split_strategy: Division strategy: 'stratified' or 'fixed_per_subject'\n",
    "    --- For 'stratified' split_strategy ---\n",
    "    :param test_split_ratio: Proportion of the total dataset to use for the test set\n",
    "    :param validation_split_ratio: Proportion of the total dataset to use for the validation set. Will be subtracted from the training set if non-zero.\n",
    "    --- For 'fixed_per_subject' split_strategy ---\n",
    "    :param random_state: Seed for reproducibility of divisions and initializations\n",
    "    :param n_train_per_subject: Exact number of images per subject for the training set. (Ignored if SPLIT_STRATEGY is not 'fixed_per_subject')\n",
    "    --- Display print logs ---\n",
    "    :param show_logs:\n",
    "\n",
    "    :return num_classes, X_train, y_train, X_test, y_test, X_val, y_val, validation_data\n",
    "    \"\"\"\n",
    "    # --- ------------------- ---\n",
    "    # --- 2. Data Preparation ---\n",
    "    # --- ------------------- ---\n",
    "\n",
    "    if X is None or y is None or label_encoder is None:\n",
    "        raise Exception(\"No data\")\n",
    "\n",
    "    # Display model parameters\n",
    "    if show_logs:\n",
    "        print(\"Custom configuration loaded:\")\n",
    "        print(f\"  - Image Dimensions: {input_shape}\")\n",
    "        print(f\"  - Split Strategy: {split_strategy}\")\n",
    "        print(\"\\n--- Prepare data ---\")\n",
    "\n",
    "    # Normalize images in the same shape\n",
    "    X = np.array([formate_ml_image(img, input_shape[0], input_shape[1]) for img in X])\n",
    "\n",
    "    # Get the total number of classes from the label encoder\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    if show_logs: print(f\"Number of classes detected: {num_classes}\")\n",
    "\n",
    "    # --- ---------------- ---\n",
    "    # --- 3. Data Division ---\n",
    "    # --- ---------------- ---\n",
    "    if SPLIT_STRATEGY == 'stratified':\n",
    "        data_splits = data_loader.split_data_stratified(\n",
    "            X, y,\n",
    "            test_size=TEST_SPLIT_RATIO,\n",
    "            validation_size=VALIDATION_SPLIT_RATIO,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        X_train = data_splits.get('X_train')\n",
    "        y_train = data_splits.get('y_train')\n",
    "        X_val = data_splits.get('X_val')\n",
    "        y_val = data_splits.get('y_val')\n",
    "        X_test = data_splits.get('X_test')\n",
    "        y_test = data_splits.get('y_test')\n",
    "\n",
    "        if X_val is None and VALIDATION_SPLIT_RATIO > 0 and X_train is not None and len(X_train) > 0:\n",
    "             val_ratio_from_train = VALIDATION_SPLIT_RATIO / (1.0 - TEST_SPLIT_RATIO)\n",
    "             if val_ratio_from_train < 1.0:\n",
    "                 if show_logs: print(f\"Creation of the validation set from training (ratio: {val_ratio_from_train:.2f})\")\n",
    "                 X_train, X_val, y_train, y_val = train_test_split(\n",
    "                     X_train, y_train,\n",
    "                     test_size=val_ratio_from_train,\n",
    "                     random_state=RANDOM_STATE,\n",
    "                     stratify=y_train\n",
    "                 )\n",
    "             else:\n",
    "                 print(\"Warning: Inconsistent split ratios, no training data remaining after validation.\")\n",
    "\n",
    "    elif SPLIT_STRATEGY == 'fixed_per_subject':\n",
    "        X_train_full, X_test, y_train_full, y_test = data_loader.split_data_fixed_per_subject(\n",
    "            X, y,\n",
    "            n_train_per_class=N_TRAIN_PER_SUBJECT,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        if VALIDATION_SPLIT_RATIO > 0 and X_train_full is not None and len(X_train_full) > 0:\n",
    "            if show_logs: print(f\"Creation of the validation set from training (ratio: {VALIDATION_SPLIT_RATIO})\")\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_full, y_train_full,\n",
    "                test_size=VALIDATION_SPLIT_RATIO,\n",
    "                random_state=RANDOM_STATE,\n",
    "                stratify=y_train_full\n",
    "            )\n",
    "        else:\n",
    "            X_train, y_train = X_train_full, y_train_full\n",
    "            X_val, y_val = None, None\n",
    "\n",
    "    else:\n",
    "        raise Exception(f\"Error: Split strategy '{SPLIT_STRATEGY}' unrecognized.\")\n",
    "\n",
    "    if X_train is None or len(X_train) == 0:\n",
    "        raise Exception(\"Error: No training data available after split.\")\n",
    "\n",
    "    if X_val is None or len(X_val) == 0:\n",
    "        print(\"Warning: No validation data available. Training will be done without validation tracking..\")\n",
    "        validation_data = None # `fit` utilisera pas de validation\n",
    "    else:\n",
    "        validation_data = (X_val, y_val)\n",
    "        if show_logs: print(f\"Final Size - Training: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test) if X_test is not None else 0}\")\n",
    "\n",
    "    return num_classes, X_train, y_train, X_test, y_test, X_val, y_val, validation_data\n",
    "\n",
    "\n",
    "res = prepare_data_train_model(\n",
    "    X, y, label_encoder,\n",
    "    input_shape=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    split_strategy=SPLIT_STRATEGY,\n",
    "    test_split_ratio=TEST_SPLIT_RATIO,\n",
    "    validation_split_ratio=VALIDATION_SPLIT_RATIO,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_train_per_subject=N_TRAIN_PER_SUBJECT\n",
    ")\n",
    "num_classes, X_train, y_train, X_test, y_test, X_val, y_val, validation_data = res"
   ],
   "id": "778e8f233d461ee7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_model(\n",
    "    num_classes,\n",
    "    input_shape: (int, int),\n",
    "    model_save_dir='ml_models/trained/',\n",
    "    log_dir='ml_models/logs/',\n",
    "    model_name='simple_cnn_lfw_anony_v1',\n",
    "    model_architecture='simple_cnn',\n",
    "    learning_rate=0.001,\n",
    "    early_stopping_patience=10,\n",
    "    transfer_base_model_name='MobileNetV2',\n",
    "    transfer_freeze_base=True,\n",
    "    show_logs=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Create a facial recognition model.\n",
    "\n",
    "    :param num_classes: generated in prepare_data_train_model()\n",
    "    :param input_shape: same as in prepare_data_train_model()\n",
    "    --- Paths & name ---\n",
    "    :param model_save_dir: Folder to save trained ml_models, label encoder, etc.\n",
    "    :param log_dir: Folder for TensorBoard logs (optional, leave blank or None to disable)\n",
    "    :param model_name: Base name for saved files (model, logs, curves)\n",
    "    :param model_architecture: Architecture choice in ml_models.py: 'simple_cnn', 'transfer_MobileNetV2', 'transfer_ResNet50', etc.\n",
    "    --- Training Settings ---\n",
    "    :param learning_rate: Learning rate for the Adam optimizer\n",
    "    :param early_stopping_patience: Patience for EarlyStopping (number of epochs without improvement on val_accuracy before stopping). Set to 0 or a negative value to disable EarlyStopping.\n",
    "    --- For Transfer Learning (if MODEL_ARCHITECTURE starts with 'transfer_') ---    :param transfer_base_model_name:\n",
    "    :param transfer_freeze_base: Name of the base model to load from tf.keras.applications\n",
    "    --- Display print logs ---\n",
    "    :param show_logs: Should the base model weights be frozen during the first training? Set to False for fine-tuning (often requires a lower LEARNING_RATE).\n",
    "\n",
    "    :return: model, callbacks, model_filepath, summary_text\n",
    "    \"\"\"\n",
    "    # --- ------------------------ ---\n",
    "    # --- 1. Loading Configuration ---\n",
    "    # --- ------------------------ ---\n",
    "\n",
    "    # Display model parameters\n",
    "    input_shape = input_shape if len(input_shape) == 2 else input_shape[:2]\n",
    "    if show_logs:\n",
    "        print(\"Custom configuration loaded :\")\n",
    "        print(f\"  - Model Architecture: {model_architecture}\")\n",
    "        print(f\"  - Model Name: {model_name}\")\n",
    "        print(f\"  - Image Dimensions: {input_shape}\")\n",
    "\n",
    "    # Prepare output & log folder\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    if  log_dir:\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        if show_logs: print(f\"  - TensorBoard Logs Folder: {log_dir}\")\n",
    "\n",
    "    # --- --------------------- ---\n",
    "    # --- 4. Model Construction ---\n",
    "    # --- --------------------- ---\n",
    "    if show_logs: print(\"\\n--- Model Construction ---\")\n",
    "    if MODEL_ARCHITECTURE == 'simple_cnn':\n",
    "        model = ml_models.build_simple_cnn(input_shape=INPUT_SHAPE, num_classes=num_classes)\n",
    "    elif MODEL_ARCHITECTURE.startswith('transfer_'):\n",
    "        if show_logs: print(f\"Using the basic model: {TRANSFER_BASE_MODEL_NAME}, Freeze: {TRANSFER_FREEZE_BASE}\")\n",
    "        model = ml_models.build_transfer_model(input_shape=INPUT_SHAPE,\n",
    "                                               num_classes=num_classes,\n",
    "                                               base_model_name=TRANSFER_BASE_MODEL_NAME,\n",
    "                                               freeze_base=TRANSFER_FREEZE_BASE)\n",
    "    else:\n",
    "        raise Exception(f\"Error: Unrecognized model architecture in config: {MODEL_ARCHITECTURE}\")\n",
    "    if model is None:\n",
    "        raise Exception(\"Critical error while building the model. Stopping.\")\n",
    "\n",
    "    # --- -------------------- ---\n",
    "    # --- 5. Model Compilation ---\n",
    "    # --- -------------------- ---\n",
    "    if show_logs: print(\"\\n--- Compiling the model ---\")\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    if show_logs: print(\"Model compiled with Adam optimizer.\")\n",
    "    model.summary()\n",
    "\n",
    "    # Capture model summary\n",
    "    summary_io = io.StringIO()\n",
    "    model.summary(print_fn=lambda x: summary_io.write(x + \"\\n\"))\n",
    "    summary_text = summary_io.getvalue()\n",
    "\n",
    "    # --- ------------------------ ---\n",
    "    # --- 6. Configuring Callbacks ---\n",
    "    # --- ------------------------ ---\n",
    "    if show_logs: print(\"\\n--- Configuring Callbacks ---\")\n",
    "    callbacks = []\n",
    "\n",
    "    model_filename = f\"{MODEL_NAME}.h5\"\n",
    "    model_filepath = os.path.join(MODEL_SAVE_DIR, model_filename)\n",
    "    if show_logs: print(f\"  - ModelCheckpoint: Saving the best model in {model_filepath}\")\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=model_filepath,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(checkpoint_callback)\n",
    "\n",
    "    if EARLY_STOPPING_PATIENCE and EARLY_STOPPING_PATIENCE > 0:\n",
    "        if show_logs: print(f\"  - EarlyStopping: Activated with patience={EARLY_STOPPING_PATIENCE}\")\n",
    "        early_stopping_callback = EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=EARLY_STOPPING_PATIENCE,\n",
    "            mode='max',\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        callbacks.append(early_stopping_callback)\n",
    "    else:\n",
    "        if show_logs: print(\"  - EarlyStopping: Disabled.\")\n",
    "\n",
    "    if LOG_DIR:\n",
    "        tensorboard_log_dir = os.path.join(LOG_DIR, MODEL_NAME + \"_\" + time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "        if show_logs: print(f\"  - TensorBoard: Logs in {tensorboard_log_dir}\")\n",
    "        tensorboard_callback = TensorBoard(\n",
    "            log_dir=tensorboard_log_dir,\n",
    "            histogram_freq=1\n",
    "        )\n",
    "        callbacks.append(tensorboard_callback)\n",
    "    else:\n",
    "        if show_logs: print(\"  - TensorBoard: Disabled.\")\n",
    "\n",
    "    csv_log_path = os.path.join(MODEL_SAVE_DIR, f\"{MODEL_NAME}_training_log.csv\")\n",
    "    if show_logs: print(f\"  - CSVLogger: Logs in {csv_log_path}\")\n",
    "    csv_logger_callback = CSVLogger(csv_log_path, append=False)\n",
    "    callbacks.append(csv_logger_callback)\n",
    "\n",
    "    return model, callbacks, model_filepath, summary_text\n",
    "\n",
    "res = create_model(\n",
    "    num_classes,\n",
    "    input_shape=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    model_save_dir=MODEL_SAVE_DIR,\n",
    "    log_dir=LOG_DIR,\n",
    "    model_name=MODEL_NAME,\n",
    "    model_architecture=MODEL_ARCHITECTURE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "    transfer_base_model_name=TRANSFER_BASE_MODEL_NAME,\n",
    "    transfer_freeze_base=TRANSFER_FREEZE_BASE\n",
    ")\n",
    "model, callbacks, model_filepath, summary_text = res"
   ],
   "id": "68ae00f1b76de1a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _draw_accuracy_and_loss_curves2(epochs_range, acc, loss, val_acc=None, val_loss=None):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    if val_acc is not None:\n",
    "        plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    if val_loss is not None:\n",
    "        plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    return plt\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    validation_data, callbacks,\n",
    "    label_encoder,\n",
    "    model_filepath,\n",
    "    model_save_dir='ml_models/trained/',\n",
    "    model_name='simple_cnn_lfw_anony_v1',\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    show_logs=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Train facial recognition model.\n",
    "\n",
    "    :param model: from create_model()\n",
    "    :param X_train: from prepare_data_train_model()\n",
    "    :param y_train: from prepare_data_train_model()\n",
    "    :param X_test: from prepare_data_train_model()\n",
    "    :param y_test: from prepare_data_train_model()\n",
    "    :param validation_data: from prepare_data_train_model()\n",
    "    :param callbacks: from create_model()\n",
    "    :param label_encoder: from get_data_from_db()\n",
    "    :param model_filepath: from create_model()\n",
    "    :param model_save_dir: same as in create_model()\n",
    "    :param model_name: same as in create_model()\n",
    "    --- Training Settings ---\n",
    "    :param batch_size: Batch size\n",
    "    :param epochs: Maximum number of training epochs\n",
    "    --- Display print logs ---\n",
    "    :param show_logs:\n",
    "\n",
    "    :return: dict\n",
    "    \"\"\"\n",
    "    # --- ----------------- ---\n",
    "    # --- 7. Model Training ---\n",
    "    # --- ----------------- ---\n",
    "\n",
    "    # Display model parameters\n",
    "    if show_logs:\n",
    "        print(\"Custom configuration loaded:\")\n",
    "        print(f\"  - Model Name: {model_name}\")\n",
    "        print(f\"  - Epochs: {epochs}, Batch Size: {batch_size}\")\n",
    "\n",
    "    if show_logs: print(\"\\n--- Start training ---\")\n",
    "    try:\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_data=validation_data,\n",
    "            callbacks=callbacks,\n",
    "            verbose=(show_logs==True)\n",
    "        )\n",
    "        if show_logs: print(\"--- Training completed ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        encoder_save_path = os.path.join(MODEL_SAVE_DIR, f\"{MODEL_NAME}_label_encoder.joblib\")\n",
    "        print(\"\\nSaving the label encoder (even if training failed)...\")\n",
    "        data_loader.save_label_encoder(label_encoder, encoder_save_path)\n",
    "        raise Exception(f\"\\nError during training: {e}\")\n",
    "\n",
    "\n",
    "    # --- ---------------- ---\n",
    "    # --- 8. Post-Training ---\n",
    "    # --- ---------------- ---\n",
    "    encoder_save_path = os.path.join(MODEL_SAVE_DIR, f\"{MODEL_NAME}_label_encoder.joblib\")\n",
    "    if show_logs: print(\"\\n--- Saving the label encoder ---\")\n",
    "    data_loader.save_label_encoder(label_encoder, encoder_save_path)\n",
    "\n",
    "    # Evaluation\n",
    "    eval_loss, eval_acc = model.evaluate(X_test, y_test)\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    if history is not None:\n",
    "        if show_logs: print(\"\\n--- Displaying learning curves ---\")\n",
    "        try:\n",
    "            acc = history.history['accuracy']\n",
    "            loss = history.history['loss']\n",
    "            val_acc = history.history['val_accuracy'] if validation_data else None\n",
    "            val_loss = history.history['val_loss'] if validation_data else None\n",
    "            epochs_range = range(len(acc))\n",
    "\n",
    "            plt_obj = _draw_accuracy_and_loss_curves2(epochs_range, acc, loss, val_acc, val_loss)\n",
    "            buf = io.BytesIO()\n",
    "            plt_obj.savefig(buf, format='png')\n",
    "            buf.seek(0)\n",
    "            image_pil = Image.open(buf)\n",
    "\n",
    "            plot_save_path = os.path.join(model_save_dir, f\"{model_name}_training_curves.pdf\")\n",
    "            plt.savefig(plot_save_path, format='pdf', bbox_inches='tight')\n",
    "            if show_logs: print(f\"Curves saved in : {plot_save_path}\")\n",
    "        except Exception as plot_e:\n",
    "            print(f\"Error generating/saving curves: {plot_e}\")\n",
    "\n",
    "    if show_logs:\n",
    "        print(f\"The best model should be saved in : {model_filepath}\")\n",
    "        print(f\"The label encoder is saved in : {encoder_save_path}\")\n",
    "\n",
    "    return {\n",
    "        \"curves\": image_pil,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"classification_report\": report,\n",
    "        \"evaluation\": {\n",
    "            \"loss\": eval_loss,\n",
    "            \"accuracy\": eval_acc\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Start timer\n",
    "print(\"--- Starting the Training Script ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Train Model\n",
    "res = train_model(\n",
    "    model,\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    validation_data, callbacks, label_encoder, model_filepath,\n",
    "    model_save_dir=MODEL_SAVE_DIR,\n",
    "    model_name=MODEL_NAME,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "\n",
    ")\n",
    "for key, val in res.items(): print(f\"\\n{key} : {val}\")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"--- Training Script Completed in {duration:.2f} secondes ---\")"
   ],
   "id": "faeab04ffb5d7a71",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc9ee36ea101e496",
   "metadata": {},
   "source": "# Predict noised image (l'image source ne doit pas etre noised normalement)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def preprocess_single_image(\n",
    "    image_array: np.array,\n",
    "    input_shape,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Resizes, normalizes and formats a single image for prediction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        width, height, channels = input_shape\n",
    "        image = formate_ml_image(image_array, width, height, channels==3)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        print(f\"Preprocessed image, final shape: {image.shape}\")\n",
    "        return image\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found: {image_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error during image preprocessing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def predict_image(\n",
    "    image_array: np.ndarray,\n",
    "    model_save_dir: str = 'ml_models/trained/',\n",
    "    model_name: str = 'simple_cnn_lfw_anony_v1',\n",
    "    input_shape: tuple = (100, 100, 1),\n",
    "    show_logs = False,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Loads the model and encoder, predicts the identity for an image.\n",
    "\n",
    "    :param image_array: Single image as a NumPy array\n",
    "    :param model_save_dir: Directory containing the model and encoder\n",
    "    :param model_name: Base name of the model\n",
    "    :param input_shape: Tuple (H, W, C) representing the expected size\n",
    "\n",
    "    :return: predicted label (str)\n",
    "    \"\"\"\n",
    "    # --- ------------------------------- ---\n",
    "    # --- 1. Load Configuration and Paths ---\n",
    "    # --- ------------------------------- ---\n",
    "    if show_logs: print(\"--- Starting the Prediction Script ---\")\n",
    "\n",
    "    model_filepath = os.path.join(MODEL_SAVE_DIR, f\"{MODEL_NAME}.h5\")\n",
    "    encoder_filepath = os.path.join(MODEL_SAVE_DIR, f\"{MODEL_NAME}_label_encoder.joblib\")\n",
    "\n",
    "    if show_logs:\n",
    "        print(f\"  - Model used: {model_filepath}\")\n",
    "        print(f\"  - Encoder used: {encoder_filepath}\")\n",
    "        print(f\"  - Image to predict: NumPy array, shape={image_array.shape}\")\n",
    "\n",
    "    # --- ------------------------- ---\n",
    "    # --- 2. Load Model and Encoder ---\n",
    "    # --- ------------------------- ---\n",
    "    if show_logs: print(\"\\n--- Loading the model and encoder ---\")\n",
    "    if not os.path.exists(model_filepath):\n",
    "        raise Exception(f\"Error: Template file not found: {model_filepath}\")\n",
    "    model = load_model(model_filepath)\n",
    "\n",
    "    # Load the label encoder\n",
    "    label_encoder = data_loader.load_label_encoder(encoder_filepath)\n",
    "    if label_encoder is None:\n",
    "        raise Exception(\"Critical error: Unable to load label encoder.\")\n",
    "\n",
    "    # --- ----------------------------- ---\n",
    "    # --- 3. Preprocess the Input Image ---\n",
    "    # --- ----------------------------- ---\n",
    "    if show_logs: print(\"\\n--- Preprocessing of the input image ---\")\n",
    "    preprocessed_image = preprocess_single_image(image_array, input_shape)\n",
    "    if preprocessed_image is None:\n",
    "        raise Exception(\"Image preprocessing failed.\")\n",
    "\n",
    "    # --- ---------------------- ---\n",
    "    # --- 4. Make the Prediction ---\n",
    "    # --- ---------------------- ---\n",
    "    if show_logs: print(\"\\n--- Prediction ---\")\n",
    "    try:\n",
    "        prediction_probabilities = model.predict(preprocessed_image)\n",
    "\n",
    "        predicted_index = np.argmax(prediction_probabilities[0])\n",
    "        prediction_confidence = prediction_probabilities[0][predicted_index]\n",
    "\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_index])[0]\n",
    "        if show_logs:\n",
    "            print(\"\\n--- Prediction Result ---\")\n",
    "            print(f\"  - Predicted Identity (Subject ID) : {predicted_label}\")\n",
    "            print(f\"  - Trust : {prediction_confidence:.4f} ({prediction_confidence*100:.2f}%)\")\n",
    "        return predicted_label, prediction_confidence\n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "user = 43\n",
    "image_path = f\"../data/dataset-lfw_reconstructed/reconstructed_{user}_2.png\"\n",
    "image = np.array(Image.open(image_path))\n",
    "\n",
    "result = predict_image(image, INPUT_SHAPE)\n",
    "predicted_label, prediction_confidence = result\n",
    "print(f\"  - Predicted Identity (Subject ID) : {predicted_label}\")\n",
    "print(f\"  - Trust : {prediction_confidence:.4f} ({prediction_confidence*100:.2f}%)\")"
   ],
   "id": "18dbab7c7272b28",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
